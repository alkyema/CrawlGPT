# ğŸ§  CrawlGPT - Personalized Web Knowledge Chatbot

CrawlGPT is a smart, **LLM-powered personalized assistant** that learns from **websites you provide**. Just give it a URL, and it will:

âœ… Scrape the full website and related pages  
âœ… Chunk and vectorize the content  
âœ… Use **Retrieval-Augmented Generation (RAG)** to power accurate, personalized answers  
âœ… Respond with context-aware replies using **Gemini** (or other LLMs)

---

## ğŸš€ Features

- ğŸ”— **Website Scraping** â€“ Provide a URL and it fetches full text content across the main site and related links.
- ğŸ“š **Context-Aware Q&A** â€“ Ask anything about the site and get answers based on its actual content.
- ğŸ§  **RAG Implementation** â€“ Vectorizes content into embeddings and retrieves context for the LLM.
- ğŸ§ª **Gemini-Powered LLM** â€“ Uses Google's Gemini for intelligent, conversational responses.
- ğŸ› ï¸ **Pluggable Architecture** â€“ Swap LLMs (OpenAI, Local LLMs, Claude, etc.)
- ğŸ—‚ï¸ **Supports Multiple Users** â€“ Store and manage personalized website knowledge per user.

---

## ğŸ§° Tech Stack

| Layer         | Tech Used                         |
|--------------|------------------------------------|
| **LLM**       | Gemini API                         |
| **RAG Engine**| FAISS (Vector DB) + Custom Retriever |
| **Scraper**   | BeautifulSoup, Requests, urllib    |
| **Backend**   | Python (FastAPI / Flask)           |
| **Frontend**  | React.js (optional for UI)         |
| **Embedding** | SentenceTransformers / Gemini Embeddings |

---

## ğŸ§  How It Works

1. **Input URL** â User provides a URL
2. **Crawl & Scrape** â The website and related links are fetched and cleaned
3. **Chunk & Embed** â Text is broken into chunks and converted into vector embeddings
4. **Store in FAISS** â Indexed for similarity search
5. **Ask Question** â User inputs a query
6. **Retrieve Context** â Top relevant chunks are retrieved from vector DB
7. **LLM Response** â Gemini generates a context-rich answer

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/CrawlGPT.git
cd CrawlGPT
pip install -r requirements.txt
```

---

## âš™ï¸ .env Example

```env
GEMINI_API_KEY=your_gemini_api_key_here
```

---

## â–¶ï¸ Run the App

```bash
python test.py
```

Or with FastAPI:
```bash
uvicorn mainAPI:app --reload --port 8888
```

---

## ğŸ“ Folder Structure

```
CrawlGPT/
â”‚
â”œâ”€â”€ FrontEnd
    â”œâ”€â”€ ChatBot.html            # Main FrontEnd file                 
â”œâ”€â”€ BackEnd                 
    â”œâ”€â”€ mainAPI.py              # Main app file
    â”œâ”€â”€ scraper.py/             # Website scraping logic
    â”œâ”€â”€ embeddings.py/          # Embedding + FAISS functions
    â”œâ”€â”€ query_engine.py/        # Gemini API integration
    â”œâ”€â”€ data/                   # Stores raw/cleaned content
    â”œâ”€â”€ .env                    # Secrets (not committed)
    â”œâ”€â”€ requirements.txt        # Python dependencies
```

---

## ğŸ”® Future Plans

- âœ… Add OpenAI & Claude model support  
- ğŸŒ Enable multi-site comparison  
- ğŸ’¾ Add persistent DB (e.g., Qdrant, Pinecone)  
- ğŸ§‘â€ğŸ’» Build React-based chat interface  
- ğŸ” Add user auth & API rate limits

---

## ğŸ§‘â€ğŸ’» Created By

- **Satwik Kishore**  
> _Built for people who want to teach AI from their own corner of the internet._

---


> ğŸ“š â€œYour personalized AI librarian â€” trained on the web you choose.â€
